# robots.txt for thisqr.works
# Allow all search engines to crawl everything

User-agent: *
Allow: /

# Sitemap location
Sitemap: https://thisqr.works/sitemap.xml

# Specific crawl directives for major search engines
User-agent: Googlebot
Allow: /

User-agent: Bingbot
Allow: /

User-agent: DuckDuckBot
Allow: /

# Block bad bots (optional - prevents spam)
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: MJ12bot
Disallow: /

# Crawl rate (optional - prevents overload)
Crawl-delay: 1
